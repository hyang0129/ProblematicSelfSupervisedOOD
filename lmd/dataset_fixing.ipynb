{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:29:43.002652Z",
     "start_time": "2024-07-26T16:29:19.012961Z"
    }
   },
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2020 The Google Research Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Training and evaluation\"\"\"\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from ml_collections.config_flags import config_flags\n",
    "import logging\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys \n",
    "import datasets \n",
    "\n",
    "# sys.argv = = [ '--dataset', 'SMD', '--q', '0.005']\n",
    "\n",
    "# sys.argv = ['--workdir',  'results/cifar10/', '--config', 'configs/subvp/cifar10_ddpm_continuous.py',  '--mode', 'train']\n",
    "# \n",
    "#         \n",
    "\n",
    "from configs.adj.cifar10_configs_0_id import get_default_configs\n",
    "import tensorflow_datasets as tfds \n",
    "from tqdm import tqdm \n",
    "\n",
    "config = get_default_configs()\n",
    "\n",
    "config.data.dataset = 'ICML_FACE_ADJ_ID_0'\n",
    "# \n",
    "train_ds, eval_ds, _ = datasets.get_dataset(config,\n",
    "                                  uniform_dequantization=config.data.uniform_dequantization, \n",
    "                                            evaluation=True, \n",
    "                                            recon=True\n",
    "                                            )\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HongM\\PycharmProjects\\ProblematicSelfSupervisedOOD\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building train\n",
      "building test\n",
      "splits done\n",
      "Applying Filters for Adjacent OOD Benchmark\n",
      "In distribution classes are [0, 1, 2, 3, 6]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T16:29:45.050694Z",
     "start_time": "2024-07-26T16:29:43.005633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from recon_utils import IterableImageDataset\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from recon_utils import center_crop_arr\n",
    "\n",
    "for data in train_ds:\n",
    "    break \n",
    "\n",
    "\n",
    "class IterableImageDataset(torch.utils.data.IterableDataset):\n",
    "  def __init__(self, tf_dataset, image_size, center_crop=False):\n",
    "    self.tf_dataset = tf_dataset\n",
    "    self.image_size = image_size\n",
    "    self.center_crop = center_crop\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.tf_dataset)\n",
    "\n",
    "  def apply_fn(self, data):\n",
    "\n",
    "    img = Image.fromarray(data['image'].numpy())\n",
    "\n",
    "    # dataset should already be RGB\n",
    "    # if img.mode != \"RGB\":\n",
    "    #   img = img.convert(\"RGB\")\n",
    "    \n",
    "    \n",
    "\n",
    "    if self.center_crop:\n",
    "      img = center_crop_arr(img, self.image_size)\n",
    "        \n",
    "        \n",
    "\n",
    "    img = T.ToTensor()(img)\n",
    "    \n",
    "    print(img.shape)\n",
    "\n",
    "    return img\n",
    "  \n",
    "  def __iter__(self):\n",
    "    worker_info = torch.utils.data.get_worker_info()\n",
    "    if worker_info is None:  # single-process data loading, return the full iterator\n",
    "      pass\n",
    "    else:  # in a worker process\n",
    "      raise NotImplementedError('Not implemented for more than 1 worker')\n",
    "    return map(self.apply_fn, self.tf_dataset)\n",
    "  \n",
    "# img = Image.fromarray(data['image'].numpy())\n",
    "\n",
    "# np.array(img).shape\n",
    "\n",
    "ds = IterableImageDataset(train_ds, image_size=config.data.image_size, center_crop=True )\n",
    "\n",
    "\n",
    "for data in ds:\n",
    "    break \n",
    "\n",
    "\n",
    "# data[0].shape"
   ],
   "id": "99b58255519ed797",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T21:50:42.322049Z",
     "start_time": "2024-07-20T21:50:42.317050Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "eac14b8e0f60cd34",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T21:55:03.480489Z",
     "start_time": "2024-07-20T21:55:03.469488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data.shape\n",
    "\n"
   ],
   "id": "6c966fe1bbcc54b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T21:29:52.221998Z",
     "start_time": "2024-07-20T21:29:51.776389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tfds.data_source(\"food101\")\n",
    "# \n",
    "# ds = tfds.data_source('cifar10')\n",
    "\n"
   ],
   "id": "e4e912fb5324ace2",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to construct dataset \"cifar10\", builder_kwargs \"{'data_dir': None, 'file_format': <FileFormat.ARRAY_RECORD: 'array_record'>}\": File format is already set to FileFormat.TFRECORD. Got FileFormat.ARRAY_RECORD",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# tfds.data_source(\"food101\")\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mtfds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_source\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcifar10\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ProblematicSelfSupervisedOOD\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001B[0m, in \u001B[0;36m_FunctionDecorator.__call__\u001B[1;34m(self, function, instance, args, kwargs)\u001B[0m\n\u001B[0;32m    167\u001B[0m metadata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_call()\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 169\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m function(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    171\u001B[0m   metadata\u001B[38;5;241m.\u001B[39mmark_error()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ProblematicSelfSupervisedOOD\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:789\u001B[0m, in \u001B[0;36mdata_source\u001B[1;34m(name, split, data_dir, download, decoders, builder_kwargs, download_and_prepare_kwargs, try_gcs)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Gets a data source from the named dataset.\u001B[39;00m\n\u001B[0;32m    699\u001B[0m \n\u001B[0;32m    700\u001B[0m \u001B[38;5;124;03m`tfds.data_source` is a convenience method that:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    786\u001B[0m \u001B[38;5;124;03m  `dict<key: tfds.Split, value: Sequence>` otherwise.\u001B[39;00m\n\u001B[0;32m    787\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# fmt:skip\u001B[39;00m\n\u001B[0;32m    788\u001B[0m builder_kwargs \u001B[38;5;241m=\u001B[39m _set_file_format_for_data_source(builder_kwargs)\n\u001B[1;32m--> 789\u001B[0m dbuilder \u001B[38;5;241m=\u001B[39m \u001B[43m_fetch_builder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbuilder_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtry_gcs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    795\u001B[0m _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n\u001B[0;32m    796\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dbuilder\u001B[38;5;241m.\u001B[39mas_data_source(split\u001B[38;5;241m=\u001B[39msplit, decoders\u001B[38;5;241m=\u001B[39mdecoders)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ProblematicSelfSupervisedOOD\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:496\u001B[0m, in \u001B[0;36m_fetch_builder\u001B[1;34m(name, data_dir, builder_kwargs, try_gcs)\u001B[0m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m builder_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    495\u001B[0m   builder_kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m builder(name, data_dir\u001B[38;5;241m=\u001B[39mdata_dir, try_gcs\u001B[38;5;241m=\u001B[39mtry_gcs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbuilder_kwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:79\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[1;32m---> 79\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ProblematicSelfSupervisedOOD\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001B[0m, in \u001B[0;36m_FunctionDecorator.__call__\u001B[1;34m(self, function, instance, args, kwargs)\u001B[0m\n\u001B[0;32m    167\u001B[0m metadata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_call()\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 169\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m function(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    171\u001B[0m   metadata\u001B[38;5;241m.\u001B[39mmark_error()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ProblematicSelfSupervisedOOD\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:220\u001B[0m, in \u001B[0;36mbuilder\u001B[1;34m(name, try_gcs, **builder_kwargs)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m:\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m py_utils\u001B[38;5;241m.\u001B[39mtry_reraise(\n\u001B[0;32m    218\u001B[0m       prefix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFailed to construct \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mget_dataset_repr()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    219\u001B[0m   ):\n\u001B[1;32m--> 220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbuilder_kwargs)  \u001B[38;5;66;03m# pytype: disable=not-instantiable\u001B[39;00m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;66;03m# If neither the code nor the files are found, raise DatasetNotFoundError\u001B[39;00m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m not_found_error\n",
      "File \u001B[1;32m~\\PycharmProjects\\ProblematicSelfSupervisedOOD\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:289\u001B[0m, in \u001B[0;36mbuilder_init.<locals>.decorator\u001B[1;34m(function, dsbuilder, args, kwargs)\u001B[0m\n\u001B[0;32m    287\u001B[0m _thread_id_to_builder_init_count[metadata\u001B[38;5;241m.\u001B[39mthread_id] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 289\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m function(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    291\u001B[0m   metadata\u001B[38;5;241m.\u001B[39mmark_error()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ProblematicSelfSupervisedOOD\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1371\u001B[0m, in \u001B[0;36mFileReaderBuilder.__init__\u001B[1;34m(self, file_format, **kwargs)\u001B[0m\n\u001B[0;32m   1360\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Initializes an instance of FileReaderBuilder.\u001B[39;00m\n\u001B[0;32m   1361\u001B[0m \n\u001B[0;32m   1362\u001B[0m \u001B[38;5;124;03mCallers must pass arguments as keyword arguments.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1368\u001B[0m \u001B[38;5;124;03m  **kwargs: Arguments passed to `DatasetBuilder`.\u001B[39;00m\n\u001B[0;32m   1369\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1370\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1371\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_file_format\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_format\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ProblematicSelfSupervisedOOD\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_info.py:470\u001B[0m, in \u001B[0;36mDatasetInfo.set_file_format\u001B[1;34m(self, file_format, override)\u001B[0m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;66;03m# If the file format has been set once, file format should be consistent\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m override \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_format \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_format \u001B[38;5;241m!=\u001B[39m file_format:\n\u001B[1;32m--> 470\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    471\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile format is already set to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_format\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_format\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    472\u001B[0m   )\n\u001B[0;32m    473\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m override \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fully_initialized:\n\u001B[0;32m    474\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    475\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot override the file format \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    476\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhen the DatasetInfo is already fully initialized!\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    477\u001B[0m   )\n",
      "\u001B[1;31mValueError\u001B[0m: Failed to construct dataset \"cifar10\", builder_kwargs \"{'data_dir': None, 'file_format': <FileFormat.ARRAY_RECORD: 'array_record'>}\": File format is already set to FileFormat.TFRECORD. Got FileFormat.ARRAY_RECORD"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:38:53.462956Z",
     "start_time": "2024-07-16T20:38:41.194283Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d076ddc093f11acc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80132679c4aa4d8fa1de5f2b8ad7aa0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "W&B sync reduced upload amount by 20.6%             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>info</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>info</td><td>1</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">testing2</strong> at: <a href='https://wandb.ai/hy3134-rochester-institute-of-technology/unsuper/runs/1l1skfja' target=\"_blank\">https://wandb.ai/hy3134-rochester-institute-of-technology/unsuper/runs/1l1skfja</a><br/> View project at: <a href='https://wandb.ai/hy3134-rochester-institute-of-technology/unsuper' target=\"_blank\">https://wandb.ai/hy3134-rochester-institute-of-technology/unsuper</a><br/>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240716_163549-1l1skfja\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T18:30:19.220055Z",
     "start_time": "2024-07-10T18:30:19.038362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "# ds = tfds.load('cars196', split='train', shuffle_files=True)\n",
    "# \n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "89cb5bfd10a5cc47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 64, 3), dtype=uint8, numpy=\n",
       "array([[[ 70,  70,  70],\n",
       "        [ 76,  76,  76],\n",
       "        [ 80,  80,  80],\n",
       "        ...,\n",
       "        [ 46,  46,  46],\n",
       "        [ 42,  42,  42],\n",
       "        [ 41,  41,  41]],\n",
       "\n",
       "       [[ 67,  67,  67],\n",
       "        [ 67,  67,  67],\n",
       "        [ 67,  67,  67],\n",
       "        ...,\n",
       "        [ 50,  50,  50],\n",
       "        [ 46,  46,  46],\n",
       "        [ 42,  42,  42]],\n",
       "\n",
       "       [[ 59,  59,  59],\n",
       "        [ 56,  56,  56],\n",
       "        [ 55,  55,  55],\n",
       "        ...,\n",
       "        [ 53,  53,  53],\n",
       "        [ 50,  50,  50],\n",
       "        [ 45,  45,  45]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 82,  82,  82],\n",
       "        [ 78,  78,  78],\n",
       "        [ 71,  71,  71],\n",
       "        ...,\n",
       "        [ 75,  75,  75],\n",
       "        [ 57,  57,  57],\n",
       "        [ 44,  44,  44]],\n",
       "\n",
       "       [[ 77,  77,  77],\n",
       "        [ 77,  77,  77],\n",
       "        [ 79,  79,  79],\n",
       "        ...,\n",
       "        [ 92,  92,  92],\n",
       "        [ 75,  75,  75],\n",
       "        [ 59,  59,  59]],\n",
       "\n",
       "       [[ 77,  77,  77],\n",
       "        [ 74,  74,  74],\n",
       "        [ 76,  76,  76],\n",
       "        ...,\n",
       "        [108, 108, 108],\n",
       "        [ 99,  99,  99],\n",
       "        [ 82,  82,  82]]], dtype=uint8)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T21:25:19.803971Z",
     "start_time": "2024-07-20T21:25:19.275866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(data['image'].numpy())\n",
    "\n",
    "\n",
    "# data['label']"
   ],
   "id": "e4f4f479ca7a856",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T18:34:39.638038Z",
     "start_time": "2024-07-10T18:34:39.624039Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install matplotlib",
   "id": "9bd7d6f5a8e4bde7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T21:29:20.610235Z",
     "start_time": "2024-07-02T21:29:20.605209Z"
    }
   },
   "cell_type": "code",
   "source": "                 ",
   "id": "6399c7874997cd00",
   "outputs": [],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
